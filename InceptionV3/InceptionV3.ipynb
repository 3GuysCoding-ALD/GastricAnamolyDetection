{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fantastic-gardening",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from sklearn.utils import shuffle\n",
    "import keras\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Activation\n",
    "from keras.layers import Conv2D, AveragePooling2D\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sea\n",
    "import tensorflow.keras.applications as Applications\n",
    "import tensorflow.keras.preprocessing.image as ImagePreprocessing\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Dense ,MaxPool2D ,BatchNormalization,Flatten \n",
    "from sklearn.model_selection import KFold\n",
    "from PIL import Image\n",
    "import importlib.util\n",
    "import random as rn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from shutil import copyfile\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "equivalent-inquiry",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = 0.7\n",
    "val_split = 0.15\n",
    "test_split = 0.15\n",
    "main_dir = 'D:/Academic_PC/Sem 4/Programming_challenge2/'\n",
    "original_ds_path = main_dir+'kvasir-dataset-v2/'\n",
    "train_ds_path = original_ds_path+'train/'\n",
    "val_ds_path = original_ds_path+'validate/'\n",
    "test_ds_path = original_ds_path+'test/'\n",
    "base_dir = main_dir+'Xception/'\n",
    "losses_dir = base_dir+'losses/'\n",
    "model_save= base_dir+'model_saves/'\n",
    "seed = 49\n",
    "size_img = (224,224) #size choosen to preserve the aspect ratio\n",
    "input_size = (224,224,3)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aging-louis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "destroyed-waste",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(featurewise_center=True,\n",
    "                               samplewise_center=True,\n",
    "                               featurewise_std_normalization=True,\n",
    "                               samplewise_std_normalization=True,\n",
    "                               zca_whitening=False,\n",
    "                               zca_epsilon=1e-06,\n",
    "                               rotation_range=40,\n",
    "                               width_shift_range=0.2,\n",
    "                               height_shift_range=0.2, \n",
    "                               brightness_range=None, \n",
    "                               shear_range=0.2, \n",
    "                               zoom_range=0.2,\n",
    "                               channel_shift_range=0.0, \n",
    "                               fill_mode='nearest', \n",
    "                               cval=0.0, \n",
    "                               horizontal_flip=True,\n",
    "                               vertical_flip=True, \n",
    "                               rescale=1./255, \n",
    "                               preprocessing_function=None,\n",
    "                               validation_split=0.15\n",
    "    )\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "north-surprise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5599 images belonging to 8 classes.\n",
      "Found 1200 images belonging to 8 classes.\n",
      "Found 1200 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(directory=train_ds_path,\n",
    "                                                    target_size=size_img,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    shuffle=True, \n",
    "                                                    seed=seed,\n",
    "                                                    )\n",
    "val_generator = val_datagen.flow_from_directory(directory=val_ds_path,\n",
    "                                                    target_size=size_img,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    shuffle=True, \n",
    "                                                    seed=seed,\n",
    "                                                    )\n",
    "test_generator = test_datagen.flow_from_directory(directory=test_ds_path,\n",
    "                                                    target_size=size_img,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    shuffle=True, \n",
    "                                                    seed=seed,\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "entire-converter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 111, 111, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 111, 111, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 111, 111, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 109, 109, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 109, 109, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 109, 109, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 109, 109, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 109, 109, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 109, 109, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 54, 54, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 54, 54, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 54, 54, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 54, 54, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 52, 52, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 52, 52, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 52, 52, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 25, 25, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 25, 25, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 25, 25, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 25, 25, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 25, 25, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 25, 25, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 25, 25, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 25, 25, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 25, 25, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 25, 25, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 25, 25, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 25, 25, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 25, 25, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 25, 25, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 25, 25, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 25, 25, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 25, 25, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 25, 25, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 25, 25, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 25, 25, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 25, 25, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 25, 25, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 25, 25, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 25, 25, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 25, 25, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 25, 25, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 25, 25, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 25, 25, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 25, 25, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 25, 25, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 25, 25, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 25, 25, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 25, 25, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 25, 25, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 25, 25, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 25, 25, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 25, 25, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 25, 25, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 25, 25, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 25, 25, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 25, 25, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 25, 25, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 25, 25, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 25, 25, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 25, 25, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 25, 25, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 25, 25, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 25, 25, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 25, 25, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 25, 25, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 25, 25, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 25, 25, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 25, 25, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 25, 25, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 25, 25, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 25, 25, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 25, 25, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 25, 25, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 25, 25, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 25, 25, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 25, 25, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 12, 12, 96)   82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 12, 12, 384)  1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 12, 12, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 12, 12, 384)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 12, 12, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 12, 12, 128)  384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 12, 12, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 12, 12, 128)  114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 12, 12, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 12, 12, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 12, 12, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 12, 12, 128)  384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 12, 12, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 12, 12, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 12, 12, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 12, 12, 128)  114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 12, 12, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 12, 12, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 12, 12, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 12, 12, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 12, 12, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 12, 12, 192)  172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 12, 12, 192)  172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 12, 12, 192)  576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 12, 12, 192)  576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 12, 12, 192)  576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 12, 12, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 12, 12, 192)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 12, 12, 192)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 12, 12, 192)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 12, 12, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 12, 12, 160)  480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 12, 12, 160)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 12, 12, 160)  179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 12, 12, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 12, 12, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 12, 12, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 12, 12, 160)  480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 12, 12, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 12, 12, 160)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 12, 12, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 12, 12, 160)  179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 12, 12, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 12, 12, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 12, 12, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 12, 12, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 12, 12, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 12, 12, 192)  215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 12, 12, 192)  215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 12, 12, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 12, 12, 192)  576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 12, 12, 192)  576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 12, 12, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 12, 12, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 12, 12, 192)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 12, 12, 192)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 12, 12, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 12, 12, 160)  480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 12, 12, 160)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 12, 12, 160)  179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 12, 12, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 12, 12, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 12, 12, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 12, 12, 160)  480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 12, 12, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 12, 12, 160)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 12, 12, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 12, 12, 160)  179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 12, 12, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 12, 12, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 12, 12, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 12, 12, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 12, 12, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 12, 12, 192)  215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 12, 12, 192)  215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 12, 12, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 12, 12, 192)  576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 12, 12, 192)  576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 12, 12, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 12, 12, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 12, 12, 192)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 12, 12, 192)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 12, 12, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 12, 12, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 12, 12, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 12, 12, 192)  258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 12, 12, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 12, 12, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 12, 12, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 12, 12, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 12, 12, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 12, 12, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 12, 12, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 12, 12, 192)  258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 12, 12, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 12, 12, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 12, 12, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 12, 12, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 12, 12, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 12, 12, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 12, 12, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 12, 12, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 12, 12, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 12, 12, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 12, 12, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 12, 12, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 12, 12, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 12, 12, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 12, 12, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 12, 12, 192)  576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 12, 12, 192)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 12, 12, 192)  258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 12, 12, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 12, 12, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 12, 12, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 12, 12, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 12, 12, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 12, 12, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 12, 12, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 5, 5, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 5, 5, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 5, 5, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 5, 5, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 5, 5, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 5, 5, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 5, 5, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 5, 5, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 5, 5, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 5, 5, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 5, 5, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 5, 5, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 5, 5, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 5, 5, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 5, 5, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 5, 5, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 5, 5, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 5, 5, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 5, 5, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 5, 5, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 5, 5, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 5, 5, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 5, 5, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 5, 5, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 5, 5, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 5, 5, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 5, 5, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 5, 5, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 5, 5, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 5, 5, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 5, 5, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 5, 5, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 5, 5, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 5, 5, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 5, 5, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 5, 5, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 5, 5, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 5, 5, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 5, 5, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 5, 5, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 5, 5, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 5, 5, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 5, 5, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 5, 5, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 5, 5, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 5, 5, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 5, 5, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 5, 5, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 5, 5, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 5, 5, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 5, 5, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 5, 5, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Base_Model = tf.keras.applications.InceptionV3(input_tensor=tf.keras.Input(shape=input_size),\n",
    "                      weights='imagenet',\n",
    "                      include_top=False)\n",
    "\n",
    "Base_Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "foster-superior",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in Base_Model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "clinical-channel",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_layer = Base_Model.get_layer('mixed7')\n",
    "conn_output = conn_layer.output\n",
    "x = conn_output \n",
    "x = Conv2D(512,(3,3),activation='relu')(x)\n",
    "x = Conv2D(512,(3,3),activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = Dense(512,activation='relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(128,activation='relu')(x)\n",
    "predictions = Dense(8,activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "gross-bridal",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=Base_Model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fifty-brazilian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 111, 111, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 111, 111, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 111, 111, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 109, 109, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 109, 109, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 109, 109, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 109, 109, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 109, 109, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 109, 109, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 54, 54, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 54, 54, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 54, 54, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 54, 54, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 52, 52, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 52, 52, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 52, 52, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 25, 25, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 25, 25, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 25, 25, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 25, 25, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 25, 25, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 25, 25, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 25, 25, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 25, 25, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 25, 25, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 25, 25, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 25, 25, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 25, 25, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 25, 25, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 25, 25, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 25, 25, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 25, 25, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 25, 25, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 25, 25, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 25, 25, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 25, 25, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 25, 25, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 25, 25, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 25, 25, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 25, 25, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 25, 25, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 25, 25, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 25, 25, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 25, 25, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 25, 25, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 25, 25, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 25, 25, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 25, 25, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 25, 25, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 25, 25, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 25, 25, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 25, 25, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 25, 25, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 25, 25, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 25, 25, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 25, 25, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 25, 25, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 25, 25, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 25, 25, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 25, 25, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 25, 25, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 25, 25, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 25, 25, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 25, 25, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 25, 25, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 25, 25, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 25, 25, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 25, 25, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 25, 25, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 25, 25, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 25, 25, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 25, 25, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 25, 25, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 25, 25, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 25, 25, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 25, 25, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 25, 25, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 12, 12, 96)   82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 12, 12, 384)  1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 12, 12, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 12, 12, 384)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 12, 12, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 12, 12, 128)  384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 12, 12, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 12, 12, 128)  114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 12, 12, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 12, 12, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 12, 12, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 12, 12, 128)  384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 12, 12, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 12, 12, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 12, 12, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 12, 12, 128)  114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 12, 12, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 12, 12, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 12, 12, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 12, 12, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 12, 12, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 12, 12, 192)  172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 12, 12, 192)  172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 12, 12, 192)  576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 12, 12, 192)  576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 12, 12, 192)  576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 12, 12, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 12, 12, 192)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 12, 12, 192)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 12, 12, 192)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 12, 12, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 12, 12, 160)  480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 12, 12, 160)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 12, 12, 160)  179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 12, 12, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 12, 12, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 12, 12, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 12, 12, 160)  480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 12, 12, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 12, 12, 160)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 12, 12, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 12, 12, 160)  179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 12, 12, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 12, 12, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 12, 12, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 12, 12, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 12, 12, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 12, 12, 192)  215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 12, 12, 192)  215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 12, 12, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 12, 12, 192)  576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 12, 12, 192)  576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 12, 12, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 12, 12, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 12, 12, 192)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 12, 12, 192)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 12, 12, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 12, 12, 160)  480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 12, 12, 160)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 12, 12, 160)  179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 12, 12, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 12, 12, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 12, 12, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 12, 12, 160)  480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 12, 12, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 12, 12, 160)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 12, 12, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 12, 12, 160)  179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 12, 12, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 12, 12, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 12, 12, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 12, 12, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 12, 12, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 12, 12, 192)  215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 12, 12, 192)  215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 12, 12, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 12, 12, 192)  576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 12, 12, 192)  576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 12, 12, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 12, 12, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 12, 12, 192)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 12, 12, 192)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 12, 12, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 12, 12, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 12, 12, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 12, 12, 192)  258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 12, 12, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 12, 12, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 12, 12, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 12, 12, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 12, 12, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 12, 12, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 12, 12, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 12, 12, 192)  258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 12, 12, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 12, 12, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 12, 12, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 12, 12, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 12, 12, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 12, 12, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 12, 12, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 12, 12, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 12, 12, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 12, 12, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 12, 12, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 12, 12, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 12, 12, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 12, 12, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 12, 12, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 10, 10, 512)  3539456     mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 8, 8, 512)    2359808     conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 8, 8, 512)    2048        conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 512)          0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          262656      global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 512)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          65664       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 8)            1032        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 15,205,928\n",
      "Trainable params: 6,229,640\n",
      "Non-trainable params: 8,976,288\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "communist-pillow",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adamax(lr=1e-2), \n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "                       ]\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "higher-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  if not os.path.exists(base_dir+'model_saves'):\n",
    "    os.mkdir(model_save)\n",
    "except FileExistsError:\n",
    "  print('FileExists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "formal-priority",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history_list = {'initial':[],'secondary':[]}\n",
    "val_history_list = {'initial':[],'secondary':[]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "sophisticated-egypt",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "C:\\Users\\ACER\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:728: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "175/175 [==============================] - 270s 2s/step - loss: 0.8072 - accuracy: 0.6855\n",
      "Epoch 2/5\n",
      "175/175 [==============================] - 121s 689ms/step - loss: 0.5393 - accuracy: 0.7805\n",
      "Epoch 3/5\n",
      "175/175 [==============================] - 118s 672ms/step - loss: 0.4952 - accuracy: 0.8005\n",
      "Epoch 4/5\n",
      "175/175 [==============================] - 116s 661ms/step - loss: 0.4575 - accuracy: 0.8182\n",
      "Epoch 5/5\n",
      "175/175 [==============================] - 117s 668ms/step - loss: 0.4241 - accuracy: 0.8291\n",
      "38/38 [==============================] - 40s 1s/step - loss: 0.6135 - accuracy: 0.7508\n",
      "Epoch 1/5\n",
      "175/175 [==============================] - 118s 675ms/step - loss: 0.4191 - accuracy: 0.8375\n",
      "Epoch 2/5\n",
      "175/175 [==============================] - 118s 672ms/step - loss: 0.4135 - accuracy: 0.8384\n",
      "Epoch 3/5\n",
      "175/175 [==============================] - 117s 669ms/step - loss: 0.3919 - accuracy: 0.8457\n",
      "Epoch 4/5\n",
      "175/175 [==============================] - 118s 673ms/step - loss: 0.3967 - accuracy: 0.8512\n",
      "Epoch 5/5\n",
      "175/175 [==============================] - 117s 671ms/step - loss: 0.3732 - accuracy: 0.8514\n",
      "38/38 [==============================] - 16s 421ms/step - loss: 0.6725 - accuracy: 0.7617\n",
      "Epoch 1/5\n",
      "175/175 [==============================] - 119s 679ms/step - loss: 0.3546 - accuracy: 0.8603\n",
      "Epoch 2/5\n",
      "175/175 [==============================] - 118s 675ms/step - loss: 0.3596 - accuracy: 0.8582\n",
      "Epoch 3/5\n",
      "175/175 [==============================] - 117s 670ms/step - loss: 0.3596 - accuracy: 0.8546\n",
      "Epoch 4/5\n",
      "175/175 [==============================] - 118s 677ms/step - loss: 0.3524 - accuracy: 0.8653\n",
      "Epoch 5/5\n",
      "175/175 [==============================] - 119s 677ms/step - loss: 0.3318 - accuracy: 0.8685\n",
      "38/38 [==============================] - 16s 415ms/step - loss: 0.4700 - accuracy: 0.8192\n",
      "Epoch 1/5\n",
      "175/175 [==============================] - 119s 677ms/step - loss: 0.3170 - accuracy: 0.8739\n",
      "Epoch 2/5\n",
      "175/175 [==============================] - 117s 670ms/step - loss: 0.3135 - accuracy: 0.8727\n",
      "Epoch 3/5\n",
      "175/175 [==============================] - 117s 671ms/step - loss: 0.3204 - accuracy: 0.8721\n",
      "Epoch 4/5\n",
      "175/175 [==============================] - 119s 678ms/step - loss: 0.3119 - accuracy: 0.8718\n",
      "Epoch 5/5\n",
      "175/175 [==============================] - 118s 672ms/step - loss: 0.2967 - accuracy: 0.8848\n",
      "38/38 [==============================] - 16s 412ms/step - loss: 0.4608 - accuracy: 0.8400\n",
      "Epoch 1/5\n",
      "175/175 [==============================] - 118s 676ms/step - loss: 0.3041 - accuracy: 0.8775\n",
      "Epoch 2/5\n",
      "175/175 [==============================] - 119s 678ms/step - loss: 0.2955 - accuracy: 0.8832\n",
      "Epoch 3/5\n",
      "175/175 [==============================] - 118s 676ms/step - loss: 0.2964 - accuracy: 0.8841\n",
      "Epoch 4/5\n",
      "175/175 [==============================] - 118s 675ms/step - loss: 0.2700 - accuracy: 0.8887\n",
      "Epoch 5/5\n",
      "175/175 [==============================] - 118s 673ms/step - loss: 0.2869 - accuracy: 0.8853\n",
      "38/38 [==============================] - 16s 408ms/step - loss: 0.4346 - accuracy: 0.8600\n",
      "Epoch 1/5\n",
      "175/175 [==============================] - 118s 676ms/step - loss: 0.2665 - accuracy: 0.8941\n",
      "Epoch 2/5\n",
      "175/175 [==============================] - 119s 682ms/step - loss: 0.2693 - accuracy: 0.8909\n",
      "Epoch 3/5\n",
      "175/175 [==============================] - 118s 672ms/step - loss: 0.2689 - accuracy: 0.8944\n",
      "Epoch 4/5\n",
      "175/175 [==============================] - 118s 675ms/step - loss: 0.2669 - accuracy: 0.8919\n",
      "Epoch 5/5\n",
      "175/175 [==============================] - 118s 672ms/step - loss: 0.2611 - accuracy: 0.8969\n",
      "38/38 [==============================] - 16s 415ms/step - loss: 0.5147 - accuracy: 0.8375\n",
      "Epoch 1/5\n",
      "175/175 [==============================] - 121s 691ms/step - loss: 0.2612 - accuracy: 0.8937\n",
      "Epoch 2/5\n",
      "175/175 [==============================] - 118s 676ms/step - loss: 0.2399 - accuracy: 0.9028\n",
      "Epoch 3/5\n",
      "175/175 [==============================] - 119s 681ms/step - loss: 0.2389 - accuracy: 0.9043\n",
      "Epoch 4/5\n",
      "175/175 [==============================] - 118s 676ms/step - loss: 0.2438 - accuracy: 0.9039\n",
      "Epoch 5/5\n",
      "175/175 [==============================] - 117s 669ms/step - loss: 0.2344 - accuracy: 0.9057\n",
      "38/38 [==============================] - 16s 414ms/step - loss: 0.6246 - accuracy: 0.8133\n",
      "Epoch 1/5\n",
      "175/175 [==============================] - 118s 674ms/step - loss: 0.2366 - accuracy: 0.9061\n",
      "Epoch 2/5\n",
      "175/175 [==============================] - 117s 670ms/step - loss: 0.2353 - accuracy: 0.9059\n",
      "Epoch 3/5\n",
      "175/175 [==============================] - 120s 687ms/step - loss: 0.2216 - accuracy: 0.9130\n",
      "Epoch 4/5\n",
      "175/175 [==============================] - 118s 673ms/step - loss: 0.2269 - accuracy: 0.9078\n",
      "Epoch 5/5\n",
      "175/175 [==============================] - 117s 671ms/step - loss: 0.2142 - accuracy: 0.9148\n",
      "38/38 [==============================] - 16s 425ms/step - loss: 0.4853 - accuracy: 0.8617\n",
      "Epoch 1/5\n",
      "175/175 [==============================] - 119s 678ms/step - loss: 0.2236 - accuracy: 0.9093\n",
      "Epoch 2/5\n",
      "175/175 [==============================] - 117s 671ms/step - loss: 0.2233 - accuracy: 0.9119\n",
      "Epoch 3/5\n",
      "175/175 [==============================] - 116s 665ms/step - loss: 0.2079 - accuracy: 0.9186\n",
      "Epoch 4/5\n",
      "175/175 [==============================] - 116s 665ms/step - loss: 0.2053 - accuracy: 0.9168\n",
      "Epoch 5/5\n",
      "175/175 [==============================] - 116s 665ms/step - loss: 0.2138 - accuracy: 0.9194\n",
      "38/38 [==============================] - 16s 421ms/step - loss: 0.4825 - accuracy: 0.8575\n",
      "Epoch 1/5\n",
      "175/175 [==============================] - 118s 673ms/step - loss: 0.2272 - accuracy: 0.9102\n",
      "Epoch 2/5\n",
      "175/175 [==============================] - 117s 670ms/step - loss: 0.2009 - accuracy: 0.9187\n",
      "Epoch 3/5\n",
      "175/175 [==============================] - 117s 669ms/step - loss: 0.2089 - accuracy: 0.9162\n",
      "Epoch 4/5\n",
      "175/175 [==============================] - 117s 667ms/step - loss: 0.1854 - accuracy: 0.9271\n",
      "Epoch 5/5\n",
      "175/175 [==============================] - 119s 679ms/step - loss: 0.2004 - accuracy: 0.9205\n",
      "38/38 [==============================] - 16s 416ms/step - loss: 0.5518 - accuracy: 0.8592\n"
     ]
    }
   ],
   "source": [
    "for times in range(10):\n",
    "    history = model.fit(x=train_generator,\n",
    "                        epochs=5,\n",
    "                        verbose=1,\n",
    "                        )\n",
    "    \n",
    "    train_history_list['initial'].append(history)\n",
    "    \n",
    "    history = model.evaluate(x=val_generator,\n",
    "                             verbose=1,\n",
    "                             return_dict = True)\n",
    "    \n",
    "    val_history_list['initial'].append(history)\n",
    "\n",
    "    model.save_weights(model_save+str(times)+'_init.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "activated-region",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  if not os.path.exists(base_dir+'losses'):\n",
    "    os.mkdir(losses_dir)\n",
    "except FileExistsError:\n",
    "  print('Folder exists')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "statewide-comment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.8071833252906799, 0.5392740964889526, 0.49519139528274536, 0.4575112760066986, 0.42408478260040283], 'accuracy': [0.6854795217514038, 0.7804965376853943, 0.8005000948905945, 0.8181818127632141, 0.8290766477584839]}\n",
      "{'loss': [0.41912224888801575, 0.41353702545166016, 0.39194953441619873, 0.3967210650444031, 0.37316930294036865], 'accuracy': [0.8374709486961365, 0.8383640050888062, 0.8456867337226868, 0.8512234091758728, 0.8514020442962646]}\n",
      "{'loss': [0.35464605689048767, 0.3595676124095917, 0.3595797121524811, 0.35237646102905273, 0.3318018615245819], 'accuracy': [0.860332190990448, 0.8581889867782593, 0.8546168804168701, 0.865333080291748, 0.8685479760169983]}\n",
      "{'loss': [0.3169879615306854, 0.3134670853614807, 0.32040950655937195, 0.3118649125099182, 0.29670748114585876], 'accuracy': [0.8739060759544373, 0.8726558089256287, 0.8721200227737427, 0.8717628121376038, 0.8848008513450623]}\n",
      "{'loss': [0.30409637093544006, 0.2954685091972351, 0.2963593900203705, 0.27001842856407166, 0.2868783473968506], 'accuracy': [0.8774781227111816, 0.8831934332847595, 0.8840864300727844, 0.8887301087379456, 0.8853366374969482]}\n",
      "{'loss': [0.26652956008911133, 0.2692877948284149, 0.2689022719860077, 0.2668931782245636, 0.2610720992088318], 'accuracy': [0.8940882086753845, 0.890873372554779, 0.8944454193115234, 0.8919450044631958, 0.8969458937644958]}\n",
      "{'loss': [0.2612293064594269, 0.2398839294910431, 0.23894597589969635, 0.2437903732061386, 0.23436811566352844], 'accuracy': [0.8937309980392456, 0.9028397798538208, 0.9042686223983765, 0.9039114117622375, 0.9056974649429321]}\n",
      "{'loss': [0.23660926520824432, 0.23533302545547485, 0.2216193974018097, 0.2269408255815506, 0.21422336995601654], 'accuracy': [0.906054675579071, 0.9058760404586792, 0.9130201935768127, 0.9078406691551208, 0.9148061871528625]}\n",
      "{'loss': [0.22357505559921265, 0.22334174811840057, 0.20791366696357727, 0.20531326532363892, 0.21382944285869598], 'accuracy': [0.9092695116996765, 0.911948561668396, 0.9185568690299988, 0.916770875453949, 0.9194499254226685]}\n",
      "{'loss': [0.22722822427749634, 0.2009008526802063, 0.20886485278606415, 0.18543954193592072, 0.20044609904289246], 'accuracy': [0.9101625084877014, 0.9187355041503906, 0.9162350296974182, 0.927129864692688, 0.9205214977264404]}\n",
      "{'loss': 0.6134650111198425, 'accuracy': 0.7508333325386047}\n",
      "{'loss': 0.67250657081604, 'accuracy': 0.7616666555404663}\n",
      "{'loss': 0.46995240449905396, 'accuracy': 0.8191666603088379}\n",
      "{'loss': 0.4607732594013214, 'accuracy': 0.8399999737739563}\n",
      "{'loss': 0.4345782399177551, 'accuracy': 0.8600000143051147}\n",
      "{'loss': 0.5146889090538025, 'accuracy': 0.8374999761581421}\n",
      "{'loss': 0.6245717406272888, 'accuracy': 0.8133333325386047}\n",
      "{'loss': 0.48531392216682434, 'accuracy': 0.8616666793823242}\n",
      "{'loss': 0.48248594999313354, 'accuracy': 0.8575000166893005}\n",
      "{'loss': 0.5517873167991638, 'accuracy': 0.85916668176651}\n"
     ]
    }
   ],
   "source": [
    "train_history = []\n",
    "for each in train_history_list['initial']:\n",
    "  print(each.history)\n",
    "  train_history.append(each.history)\n",
    "\n",
    "val_history = []\n",
    "for each in val_history_list['initial']:\n",
    "  print(each)\n",
    "  val_history.append(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "opening-aging",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(losses_dir+'train_history.json','w') as f0:\n",
    "  json.dump(train_history,f0)\n",
    "\n",
    "with open(losses_dir+'val_history.json','w') as f0:\n",
    "  json.dump(val_history,f0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "industrial-fluid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x000002741A4D4E50>\n",
      "1 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002741A6F9C40>\n",
      "2 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000002741A70C1F0>\n",
      "3 <tensorflow.python.keras.layers.core.Activation object at 0x000002741A70C790>\n",
      "4 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027432769A30>\n",
      "5 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x00000274327D8C70>\n",
      "6 <tensorflow.python.keras.layers.core.Activation object at 0x00000274327E0D30>\n",
      "7 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000274327E08B0>\n",
      "8 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x00000274327E6850>\n",
      "9 <tensorflow.python.keras.layers.core.Activation object at 0x0000027432815580>\n",
      "10 <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x00000274328154C0>\n",
      "11 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027432815FA0>\n",
      "12 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000002743281AE50>\n",
      "13 <tensorflow.python.keras.layers.core.Activation object at 0x0000027432851E20>\n",
      "14 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027432851460>\n",
      "15 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000002743285AF10>\n",
      "16 <tensorflow.python.keras.layers.core.Activation object at 0x0000027432882520>\n",
      "17 <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x00000274328828B0>\n",
      "18 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000274329215B0>\n",
      "19 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027432932B20>\n",
      "20 <tensorflow.python.keras.layers.core.Activation object at 0x0000027432952550>\n",
      "21 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000274328BDC40>\n",
      "22 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027432952850>\n",
      "23 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x00000274328CA490>\n",
      "24 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000002743295BF40>\n",
      "25 <tensorflow.python.keras.layers.core.Activation object at 0x00000274328E5E80>\n",
      "26 <tensorflow.python.keras.layers.core.Activation object at 0x0000027432984610>\n",
      "27 <tensorflow.python.keras.layers.pooling.AveragePooling2D object at 0x00000274329BC190>\n",
      "28 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027432882D60>\n",
      "29 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000274328EDA90>\n",
      "30 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027432984310>\n",
      "31 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000274329BCD90>\n",
      "32 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x00000274328B4820>\n",
      "33 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x00000274328F3E50>\n",
      "34 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x00000274329973D0>\n",
      "35 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x00000274329C32B0>\n",
      "36 <tensorflow.python.keras.layers.core.Activation object at 0x00000274328BDA90>\n",
      "37 <tensorflow.python.keras.layers.core.Activation object at 0x00000274329215E0>\n",
      "38 <tensorflow.python.keras.layers.core.Activation object at 0x000002743298C3A0>\n",
      "39 <tensorflow.python.keras.layers.core.Activation object at 0x00000274329EFB50>\n",
      "40 <tensorflow.python.keras.layers.merge.Concatenate object at 0x00000274329EFB20>\n",
      "41 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027432A94670>\n",
      "42 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027432AA51C0>\n",
      "43 <tensorflow.python.keras.layers.core.Activation object at 0x0000027432ABFBB0>\n",
      "44 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027432A285E0>\n",
      "45 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027432AC6850>\n",
      "46 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027432A2F310>\n",
      "47 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027432ACDB80>\n",
      "48 <tensorflow.python.keras.layers.core.Activation object at 0x0000027432A5AAC0>\n",
      "49 <tensorflow.python.keras.layers.core.Activation object at 0x0000027432AF0E20>\n",
      "50 <tensorflow.python.keras.layers.pooling.AveragePooling2D object at 0x0000027432B2A5B0>\n",
      "51 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000274329F6F40>\n",
      "52 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027432A5AC10>\n",
      "53 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027432AF9C10>\n",
      "54 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027432B2AD00>\n",
      "55 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027432A23460>\n",
      "56 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027432A6A670>\n",
      "57 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027432AFFE20>\n",
      "58 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027432B32EE0>\n",
      "59 <tensorflow.python.keras.layers.core.Activation object at 0x0000027432A28070>\n",
      "60 <tensorflow.python.keras.layers.core.Activation object at 0x0000027432A8DBB0>\n",
      "61 <tensorflow.python.keras.layers.core.Activation object at 0x0000027432B2A5E0>\n",
      "62 <tensorflow.python.keras.layers.core.Activation object at 0x0000027432B5DF10>\n",
      "63 <tensorflow.python.keras.layers.merge.Concatenate object at 0x0000027432B5DE50>\n",
      "64 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027432BFC580>\n",
      "65 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027432C04D00>\n",
      "66 <tensorflow.python.keras.layers.core.Activation object at 0x0000027432C2FB80>\n",
      "67 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027432B96B20>\n",
      "68 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027432C2F7C0>\n",
      "69 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027432BA9A90>\n",
      "70 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027432C3D370>\n",
      "71 <tensorflow.python.keras.layers.core.Activation object at 0x0000027432BCAEE0>\n",
      "72 <tensorflow.python.keras.layers.core.Activation object at 0x0000027432C64940>\n",
      "73 <tensorflow.python.keras.layers.pooling.AveragePooling2D object at 0x0000027432C9D430>\n",
      "74 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027432B631C0>\n",
      "75 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027432BCA2E0>\n",
      "76 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027432C86670>\n",
      "77 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027432C9D520>\n",
      "78 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027432B90580>\n",
      "79 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027432BD0EB0>\n",
      "80 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027432C6F400>\n",
      "81 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027432CC7E50>\n",
      "82 <tensorflow.python.keras.layers.core.Activation object at 0x0000027432B96D90>\n",
      "83 <tensorflow.python.keras.layers.core.Activation object at 0x0000027432BFC280>\n",
      "84 <tensorflow.python.keras.layers.core.Activation object at 0x0000027432C95E80>\n",
      "85 <tensorflow.python.keras.layers.core.Activation object at 0x0000027432CCEDF0>\n",
      "86 <tensorflow.python.keras.layers.merge.Concatenate object at 0x0000027432CCECA0>\n",
      "87 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027432D09F10>\n",
      "88 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027432D19490>\n",
      "89 <tensorflow.python.keras.layers.core.Activation object at 0x0000027432D344C0>\n",
      "90 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027432D3CD30>\n",
      "91 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027432D41CD0>\n",
      "92 <tensorflow.python.keras.layers.core.Activation object at 0x0000027432D6F280>\n",
      "93 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027432CCEC70>\n",
      "94 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027432D6F310>\n",
      "95 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027432D026A0>\n",
      "96 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027432D74550>\n",
      "97 <tensorflow.python.keras.layers.core.Activation object at 0x0000027432D02D90>\n",
      "98 <tensorflow.python.keras.layers.core.Activation object at 0x0000027432DA2580>\n",
      "99 <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x0000027432DA24C0>\n",
      "100 <tensorflow.python.keras.layers.merge.Concatenate object at 0x0000027432DA2FA0>\n",
      "101 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027432E728B0>\n",
      "102 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027432E85DF0>\n",
      "103 <tensorflow.python.keras.layers.core.Activation object at 0x0000027432E77D90>\n",
      "104 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027432EAE6D0>\n",
      "105 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027432EB3700>\n",
      "106 <tensorflow.python.keras.layers.core.Activation object at 0x0000027432ED8AC0>\n",
      "107 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027432DDA0D0>\n",
      "108 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027432EDF190>\n",
      "109 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027432DE0400>\n",
      "110 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027432EE6A60>\n",
      "111 <tensorflow.python.keras.layers.core.Activation object at 0x0000027432E0C580>\n",
      "112 <tensorflow.python.keras.layers.core.Activation object at 0x0000027432F09790>\n",
      "113 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027432E0C3D0>\n",
      "114 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027432F107F0>\n",
      "115 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027432E13640>\n",
      "116 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027432F18D00>\n",
      "117 <tensorflow.python.keras.layers.core.Activation object at 0x0000027432E3F580>\n",
      "118 <tensorflow.python.keras.layers.core.Activation object at 0x0000027432F3CD60>\n",
      "119 <tensorflow.python.keras.layers.pooling.AveragePooling2D object at 0x0000027432F76A90>\n",
      "120 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027432DA5BE0>\n",
      "121 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027432E3F4C0>\n",
      "122 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027432F428B0>\n",
      "123 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027432F76F40>\n",
      "124 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027432DD4F10>\n",
      "125 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027432E46BE0>\n",
      "126 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027432F492B0>\n",
      "127 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027432F7D580>\n",
      "128 <tensorflow.python.keras.layers.core.Activation object at 0x0000027432DDA4F0>\n",
      "129 <tensorflow.python.keras.layers.core.Activation object at 0x0000027432E72520>\n",
      "130 <tensorflow.python.keras.layers.core.Activation object at 0x0000027432F76F10>\n",
      "131 <tensorflow.python.keras.layers.core.Activation object at 0x0000027432FA79D0>\n",
      "132 <tensorflow.python.keras.layers.merge.Concatenate object at 0x0000027432FB0370>\n",
      "133 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027433080370>\n",
      "134 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027433080520>\n",
      "135 <tensorflow.python.keras.layers.core.Activation object at 0x00000274330AF9D0>\n",
      "136 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000274330B67C0>\n",
      "137 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x00000274330BC490>\n",
      "138 <tensorflow.python.keras.layers.core.Activation object at 0x000002746DE07EE0>\n",
      "139 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027432FE1B20>\n",
      "140 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002746BE5B4F0>\n",
      "141 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027433001FD0>\n",
      "142 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x00000274330F5280>\n",
      "143 <tensorflow.python.keras.layers.core.Activation object at 0x0000027433016DF0>\n",
      "144 <tensorflow.python.keras.layers.core.Activation object at 0x0000027433114730>\n",
      "145 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027433016FA0>\n",
      "146 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000274331147C0>\n",
      "147 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x00000274330271F0>\n",
      "148 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027433122430>\n",
      "149 <tensorflow.python.keras.layers.core.Activation object at 0x0000027433048700>\n",
      "150 <tensorflow.python.keras.layers.core.Activation object at 0x0000027433149BE0>\n",
      "151 <tensorflow.python.keras.layers.pooling.AveragePooling2D object at 0x0000027433182DF0>\n",
      "152 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027432FB06D0>\n",
      "153 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027433048820>\n",
      "154 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027433150670>\n",
      "155 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027433182880>\n",
      "156 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027432FDAA90>\n",
      "157 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000002743305B340>\n",
      "158 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027433155460>\n",
      "159 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027433189970>\n",
      "160 <tensorflow.python.keras.layers.core.Activation object at 0x0000027432FE1A60>\n",
      "161 <tensorflow.python.keras.layers.core.Activation object at 0x000002743307CAC0>\n",
      "162 <tensorflow.python.keras.layers.core.Activation object at 0x000002743317AC40>\n",
      "163 <tensorflow.python.keras.layers.core.Activation object at 0x00000274331B3400>\n",
      "164 <tensorflow.python.keras.layers.merge.Concatenate object at 0x00000274331B3310>\n",
      "165 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027433287550>\n",
      "166 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000002743328DA30>\n",
      "167 <tensorflow.python.keras.layers.core.Activation object at 0x00000274332B9AF0>\n",
      "168 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000274332B97F0>\n",
      "169 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x00000274332CB340>\n",
      "170 <tensorflow.python.keras.layers.core.Activation object at 0x00000274332C0D60>\n",
      "171 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000274331ED910>\n",
      "172 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000274332F1EE0>\n",
      "173 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x00000274331FF520>\n",
      "174 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x00000274332F90D0>\n",
      "175 <tensorflow.python.keras.layers.core.Activation object at 0x00000274332188B0>\n",
      "176 <tensorflow.python.keras.layers.core.Activation object at 0x000002743331EDC0>\n",
      "177 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000274332202E0>\n",
      "178 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027433325880>\n",
      "179 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027433226DF0>\n",
      "180 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000002743332BA90>\n",
      "181 <tensorflow.python.keras.layers.core.Activation object at 0x0000027433252400>\n",
      "182 <tensorflow.python.keras.layers.core.Activation object at 0x000002743334FCD0>\n",
      "183 <tensorflow.python.keras.layers.pooling.AveragePooling2D object at 0x00000274333882B0>\n",
      "184 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000274331B3460>\n",
      "185 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000274332523A0>\n",
      "186 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027433357F70>\n",
      "187 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027433388DC0>\n",
      "188 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x00000274331E68E0>\n",
      "189 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027433257A30>\n",
      "190 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027433381EB0>\n",
      "191 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027433390D60>\n",
      "192 <tensorflow.python.keras.layers.core.Activation object at 0x00000274331E63D0>\n",
      "193 <tensorflow.python.keras.layers.core.Activation object at 0x0000027433287F10>\n",
      "194 <tensorflow.python.keras.layers.core.Activation object at 0x0000027433388460>\n",
      "195 <tensorflow.python.keras.layers.core.Activation object at 0x00000274333BE220>\n",
      "196 <tensorflow.python.keras.layers.merge.Concatenate object at 0x00000274333BEDF0>\n",
      "197 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002743348F820>\n",
      "198 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000002743349F100>\n",
      "199 <tensorflow.python.keras.layers.core.Activation object at 0x00000274334C0A30>\n",
      "200 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000274334CA7F0>\n",
      "201 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x00000274334D0820>\n",
      "202 <tensorflow.python.keras.layers.core.Activation object at 0x00000274334F7C70>\n",
      "203 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000274333F8C10>\n",
      "204 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000274334FDA30>\n",
      "205 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x00000274333FD760>\n",
      "206 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027433503AC0>\n",
      "207 <tensorflow.python.keras.layers.core.Activation object at 0x0000027433428580>\n",
      "208 <tensorflow.python.keras.layers.core.Activation object at 0x0000027433529D30>\n",
      "209 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027433428610>\n",
      "210 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002743352F100>\n",
      "211 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000002743342FA60>\n",
      "212 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000002743353F850>\n",
      "213 <tensorflow.python.keras.layers.core.Activation object at 0x000002743345DF10>\n",
      "214 <tensorflow.python.keras.layers.core.Activation object at 0x0000027433560310>\n",
      "215 <tensorflow.python.keras.layers.pooling.AveragePooling2D object at 0x00000274335967F0>\n",
      "216 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000274333C1F40>\n",
      "217 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002743345DDF0>\n",
      "218 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027433560490>\n",
      "219 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000027433596F10>\n",
      "220 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x00000274333F2220>\n",
      "221 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000002743346F1F0>\n",
      "222 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000027433569700>\n",
      "223 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000002743359BD90>\n",
      "224 <tensorflow.python.keras.layers.core.Activation object at 0x00000274333F86D0>\n",
      "225 <tensorflow.python.keras.layers.core.Activation object at 0x000002743348F700>\n",
      "226 <tensorflow.python.keras.layers.core.Activation object at 0x0000027433596730>\n",
      "227 <tensorflow.python.keras.layers.core.Activation object at 0x00000274335CF490>\n",
      "228 <tensorflow.python.keras.layers.merge.Concatenate object at 0x00000274335CF1C0>\n",
      "229 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002747F8BE250>\n",
      "230 <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002747F8BE610>\n",
      "231 <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x000002747F8BE0A0>\n",
      "232 <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x000002747FA74EB0>\n",
      "233 <tensorflow.python.keras.layers.core.Dense object at 0x000002747FA76E20>\n",
      "234 <tensorflow.python.keras.layers.core.Dropout object at 0x000002747FA76580>\n",
      "235 <tensorflow.python.keras.layers.core.Dense object at 0x000002747FAA4430>\n",
      "236 <tensorflow.python.keras.layers.core.Dense object at 0x000002747FACEDF0>\n"
     ]
    }
   ],
   "source": [
    "for i,layer in enumerate(model.layers):\n",
    "    print(i,layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "illegal-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "raising-montgomery",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[51:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "passive-finnish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 111, 111, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 111, 111, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 111, 111, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 109, 109, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 109, 109, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 109, 109, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 109, 109, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 109, 109, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 109, 109, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 54, 54, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 54, 54, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 54, 54, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 54, 54, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 52, 52, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 52, 52, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 52, 52, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 25, 25, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 25, 25, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 25, 25, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 25, 25, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 25, 25, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 25, 25, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 25, 25, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 25, 25, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 25, 25, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 25, 25, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 25, 25, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 25, 25, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 25, 25, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 25, 25, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 25, 25, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 25, 25, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 25, 25, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 25, 25, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 25, 25, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 25, 25, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 25, 25, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 25, 25, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 25, 25, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 25, 25, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 25, 25, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 25, 25, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 25, 25, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 25, 25, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 25, 25, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 25, 25, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 25, 25, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 25, 25, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 25, 25, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 25, 25, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 25, 25, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 25, 25, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 25, 25, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 25, 25, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 25, 25, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 25, 25, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 25, 25, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 25, 25, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 25, 25, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 25, 25, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 25, 25, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 25, 25, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 25, 25, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 25, 25, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 25, 25, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 25, 25, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 25, 25, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 25, 25, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 25, 25, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 25, 25, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 25, 25, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 25, 25, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 25, 25, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 25, 25, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 25, 25, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 25, 25, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 25, 25, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 12, 12, 96)   82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 12, 12, 384)  1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 12, 12, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 12, 12, 384)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 12, 12, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 12, 12, 128)  384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 12, 12, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 12, 12, 128)  114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 12, 12, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 12, 12, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 12, 12, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 12, 12, 128)  384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 12, 12, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 12, 12, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 12, 12, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 12, 12, 128)  114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 12, 12, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 12, 12, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 12, 12, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 12, 12, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 12, 12, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 12, 12, 192)  172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 12, 12, 192)  172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 12, 12, 192)  576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 12, 12, 192)  576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 12, 12, 192)  576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 12, 12, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 12, 12, 192)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 12, 12, 192)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 12, 12, 192)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 12, 12, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 12, 12, 160)  480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 12, 12, 160)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 12, 12, 160)  179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 12, 12, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 12, 12, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 12, 12, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 12, 12, 160)  480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 12, 12, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 12, 12, 160)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 12, 12, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 12, 12, 160)  179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 12, 12, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 12, 12, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 12, 12, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 12, 12, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 12, 12, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 12, 12, 192)  215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 12, 12, 192)  215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 12, 12, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 12, 12, 192)  576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 12, 12, 192)  576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 12, 12, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 12, 12, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 12, 12, 192)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 12, 12, 192)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 12, 12, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 12, 12, 160)  480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 12, 12, 160)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 12, 12, 160)  179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 12, 12, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 12, 12, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 12, 12, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 12, 12, 160)  480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 12, 12, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 12, 12, 160)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 12, 12, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 12, 12, 160)  179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 12, 12, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 12, 12, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 12, 12, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 12, 12, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 12, 12, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 12, 12, 192)  215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 12, 12, 192)  215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 12, 12, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 12, 12, 192)  576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 12, 12, 192)  576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 12, 12, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 12, 12, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 12, 12, 192)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 12, 12, 192)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 12, 12, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 12, 12, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 12, 12, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 12, 12, 192)  258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 12, 12, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 12, 12, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 12, 12, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 12, 12, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 12, 12, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 12, 12, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 12, 12, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 12, 12, 192)  258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 12, 12, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 12, 12, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 12, 12, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 12, 12, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 12, 12, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 12, 12, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 12, 12, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 12, 12, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 12, 12, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 12, 12, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 12, 12, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 12, 12, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 12, 12, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 12, 12, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 12, 12, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 10, 10, 512)  3539456     mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 8, 8, 512)    2359808     conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 8, 8, 512)    2048        conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 512)          0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          262656      global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 512)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          65664       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 8)            1032        dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 15,205,928\n",
      "Trainable params: 14,674,200\n",
      "Non-trainable params: 531,728\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cooked-straight",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history_list = {'initial':[],'secondary':[]}\n",
    "val_history_list = {'initial':[],'secondary':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "painful-procedure",
   "metadata": {},
   "outputs": [],
   "source": [
    "from_epoch = 20\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "falling-content",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "175/175 [==============================] - 117s 670ms/step - loss: 0.1286 - accuracy: 0.9518\n",
      "Epoch 2/5\n",
      "175/175 [==============================] - 125s 716ms/step - loss: 0.1209 - accuracy: 0.9578\n",
      "Epoch 3/5\n",
      "175/175 [==============================] - 119s 680ms/step - loss: 0.1184 - accuracy: 0.9553\n",
      "Epoch 4/5\n",
      "175/175 [==============================] - 116s 665ms/step - loss: 0.1260 - accuracy: 0.9543\n",
      "Epoch 5/5\n",
      "175/175 [==============================] - 116s 665ms/step - loss: 0.1209 - accuracy: 0.9536\n",
      "38/38 [==============================] - 16s 418ms/step - loss: 0.8922 - accuracy: 0.8517\n",
      "Epoch 1/5\n",
      "175/175 [==============================] - 118s 676ms/step - loss: 0.1305 - accuracy: 0.9511\n",
      "Epoch 2/5\n",
      "175/175 [==============================] - 118s 675ms/step - loss: 0.1034 - accuracy: 0.9616\n",
      "Epoch 3/5\n",
      "175/175 [==============================] - 118s 676ms/step - loss: 0.1141 - accuracy: 0.9562\n",
      "Epoch 4/5\n",
      "175/175 [==============================] - 117s 667ms/step - loss: 0.1197 - accuracy: 0.9541\n",
      "Epoch 5/5\n",
      "175/175 [==============================] - 120s 687ms/step - loss: 0.1184 - accuracy: 0.9568\n",
      "38/38 [==============================] - 16s 412ms/step - loss: 0.8015 - accuracy: 0.8408\n",
      "Epoch 1/5\n",
      "175/175 [==============================] - 127s 727ms/step - loss: 0.1116 - accuracy: 0.9553\n",
      "Epoch 2/5\n",
      "175/175 [==============================] - 121s 691ms/step - loss: 0.1039 - accuracy: 0.9620\n",
      "Epoch 3/5\n",
      "175/175 [==============================] - 119s 678ms/step - loss: 0.1185 - accuracy: 0.9543\n",
      "Epoch 4/5\n",
      "175/175 [==============================] - 118s 676ms/step - loss: 0.1156 - accuracy: 0.9550\n",
      "Epoch 5/5\n",
      "175/175 [==============================] - 116s 664ms/step - loss: 0.1077 - accuracy: 0.9584\n",
      "38/38 [==============================] - 15s 408ms/step - loss: 0.6985 - accuracy: 0.8650\n",
      "Epoch 1/5\n",
      "175/175 [==============================] - 119s 679ms/step - loss: 0.1155 - accuracy: 0.9541\n",
      "Epoch 2/5\n",
      "175/175 [==============================] - 116s 665ms/step - loss: 0.1022 - accuracy: 0.9623\n",
      "Epoch 3/5\n",
      "175/175 [==============================] - 116s 660ms/step - loss: 0.1141 - accuracy: 0.9591\n",
      "Epoch 4/5\n",
      "175/175 [==============================] - 116s 663ms/step - loss: 0.1001 - accuracy: 0.9641\n",
      "Epoch 5/5\n",
      "175/175 [==============================] - 117s 669ms/step - loss: 0.1021 - accuracy: 0.9611\n",
      "38/38 [==============================] - 15s 405ms/step - loss: 0.5468 - accuracy: 0.8583\n",
      "Epoch 1/5\n",
      "175/175 [==============================] - 116s 664ms/step - loss: 0.1032 - accuracy: 0.9612\n",
      "Epoch 2/5\n",
      "175/175 [==============================] - 117s 667ms/step - loss: 0.1140 - accuracy: 0.9559\n",
      "Epoch 3/5\n",
      "175/175 [==============================] - 116s 663ms/step - loss: 0.1019 - accuracy: 0.9634\n",
      "Epoch 4/5\n",
      "175/175 [==============================] - 117s 667ms/step - loss: 0.0994 - accuracy: 0.9641\n",
      "Epoch 5/5\n",
      "175/175 [==============================] - 117s 667ms/step - loss: 0.1022 - accuracy: 0.9646\n",
      "38/38 [==============================] - 15s 408ms/step - loss: 0.7131 - accuracy: 0.8642\n",
      "Epoch 1/5\n",
      "175/175 [==============================] - 116s 666ms/step - loss: 0.1028 - accuracy: 0.9632\n",
      "Epoch 2/5\n",
      "175/175 [==============================] - 116s 664ms/step - loss: 0.1078 - accuracy: 0.9614\n",
      "Epoch 3/5\n",
      "175/175 [==============================] - 116s 666ms/step - loss: 0.1034 - accuracy: 0.9616\n",
      "Epoch 4/5\n",
      "175/175 [==============================] - 116s 665ms/step - loss: 0.0986 - accuracy: 0.9639\n",
      "Epoch 5/5\n",
      "175/175 [==============================] - 117s 666ms/step - loss: 0.0952 - accuracy: 0.9620\n",
      "38/38 [==============================] - 16s 410ms/step - loss: 0.6597 - accuracy: 0.8583\n",
      "Epoch 1/5\n",
      "175/175 [==============================] - 118s 675ms/step - loss: 0.0973 - accuracy: 0.9652\n",
      "Epoch 2/5\n",
      "175/175 [==============================] - 117s 670ms/step - loss: 0.1048 - accuracy: 0.9593\n",
      "Epoch 3/5\n",
      "175/175 [==============================] - 116s 666ms/step - loss: 0.1069 - accuracy: 0.9598\n",
      "Epoch 4/5\n",
      "175/175 [==============================] - 117s 671ms/step - loss: 0.0893 - accuracy: 0.9655\n",
      "Epoch 5/5\n",
      "175/175 [==============================] - 116s 664ms/step - loss: 0.1031 - accuracy: 0.9611\n",
      "38/38 [==============================] - 16s 414ms/step - loss: 0.8517 - accuracy: 0.8625\n",
      "Epoch 1/5\n",
      "175/175 [==============================] - 118s 674ms/step - loss: 0.0894 - accuracy: 0.9661\n",
      "Epoch 2/5\n",
      "175/175 [==============================] - 118s 672ms/step - loss: 0.0898 - accuracy: 0.9654\n",
      "Epoch 3/5\n",
      "175/175 [==============================] - 119s 681ms/step - loss: 0.0974 - accuracy: 0.9657\n",
      "Epoch 4/5\n",
      "175/175 [==============================] - 117s 669ms/step - loss: 0.0924 - accuracy: 0.9670\n",
      "Epoch 5/5\n",
      "175/175 [==============================] - 117s 670ms/step - loss: 0.0926 - accuracy: 0.9680\n",
      "38/38 [==============================] - 16s 418ms/step - loss: 0.9974 - accuracy: 0.8158\n",
      "Epoch 1/5\n",
      "175/175 [==============================] - 118s 673ms/step - loss: 0.1021 - accuracy: 0.9623\n",
      "Epoch 2/5\n",
      "175/175 [==============================] - 116s 662ms/step - loss: 0.0956 - accuracy: 0.9648\n",
      "Epoch 3/5\n",
      "175/175 [==============================] - 116s 665ms/step - loss: 0.0815 - accuracy: 0.9704\n",
      "Epoch 4/5\n",
      "175/175 [==============================] - 116s 665ms/step - loss: 0.0854 - accuracy: 0.9664\n",
      "Epoch 5/5\n",
      "175/175 [==============================] - 117s 668ms/step - loss: 0.0943 - accuracy: 0.9641\n",
      "38/38 [==============================] - 16s 433ms/step - loss: 0.7963 - accuracy: 0.8717\n",
      "Epoch 1/5\n",
      "175/175 [==============================] - 118s 675ms/step - loss: 0.0838 - accuracy: 0.9704\n",
      "Epoch 2/5\n",
      "175/175 [==============================] - 118s 674ms/step - loss: 0.0999 - accuracy: 0.9673\n",
      "Epoch 3/5\n",
      "175/175 [==============================] - 130s 743ms/step - loss: 0.1056 - accuracy: 0.9614\n",
      "Epoch 4/5\n",
      "175/175 [==============================] - 119s 682ms/step - loss: 0.0859 - accuracy: 0.9661\n",
      "Epoch 5/5\n",
      "175/175 [==============================] - 118s 677ms/step - loss: 0.0823 - accuracy: 0.9707\n",
      "38/38 [==============================] - 16s 408ms/step - loss: 0.9651 - accuracy: 0.8392\n"
     ]
    }
   ],
   "source": [
    "for times in range(from_epoch,from_epoch+num_epochs,1):\n",
    "    history = model.fit(x=train_generator,\n",
    "                        epochs=5,\n",
    "                        verbose=1,\n",
    "                        )\n",
    "    \n",
    "    train_history_list['secondary'].append(history)\n",
    "    \n",
    "    history = model.evaluate(x=val_generator,\n",
    "                             verbose=1,\n",
    "                             return_dict = True)\n",
    "    \n",
    "    val_history_list['secondary'].append(history)\n",
    "\n",
    "    model.save_weights(model_save+str(times)+'_secondary2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "searching-independence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.1286362111568451, 0.12087778002023697, 0.11840253323316574, 0.12600988149642944, 0.12091768532991409], 'accuracy': [0.9517771005630493, 0.9578496217727661, 0.9553491473197937, 0.9542775750160217, 0.9535631537437439]}\n",
      "{'loss': [0.13051989674568176, 0.10341537743806839, 0.11406472325325012, 0.11970222741365433, 0.11844988912343979], 'accuracy': [0.9510626792907715, 0.9616003036499023, 0.9562422037124634, 0.9540989398956299, 0.9567779898643494]}\n",
      "{'loss': [0.11157756298780441, 0.10394882410764694, 0.11854147911071777, 0.11563514173030853, 0.10773642361164093], 'accuracy': [0.9553491473197937, 0.9619575142860413, 0.9542775750160217, 0.9549919366836548, 0.9583854079246521]}\n",
      "{'loss': [0.11553586274385452, 0.10215891152620316, 0.1140812486410141, 0.1000688225030899, 0.10211154073476791], 'accuracy': [0.9540989398956299, 0.9623147249221802, 0.9590998291969299, 0.96410071849823, 0.9610644578933716]}\n",
      "{'loss': [0.1031622365117073, 0.11395549029111862, 0.10189631581306458, 0.09942729771137238, 0.10217320919036865], 'accuracy': [0.9612430930137634, 0.9558849930763245, 0.9633862972259521, 0.96410071849823, 0.9646365642547607]}\n",
      "{'loss': [0.10281839966773987, 0.10778114944696426, 0.10344148427248001, 0.09858599305152893, 0.09520121663808823], 'accuracy': [0.9632077217102051, 0.9614216685295105, 0.9616003036499023, 0.9639221429824829, 0.9619575142860413]}\n",
      "{'loss': [0.09730995446443558, 0.10480380803346634, 0.10693418979644775, 0.08925078809261322, 0.10312222689390182], 'accuracy': [0.9651723504066467, 0.9592784643173218, 0.9598142504692078, 0.9655295610427856, 0.9610644578933716]}\n",
      "{'loss': [0.08942814916372299, 0.08979339152574539, 0.0974409207701683, 0.09240748733282089, 0.09256220608949661], 'accuracy': [0.9660653471946716, 0.9653509259223938, 0.9657081365585327, 0.9669584035873413, 0.9680299758911133]}\n",
      "{'loss': [0.10206107050180435, 0.0955631211400032, 0.08154544234275818, 0.08540816605091095, 0.09429872035980225], 'accuracy': [0.9623147249221802, 0.9648151397705078, 0.9703518748283386, 0.9664225578308105, 0.96410071849823]}\n",
      "{'loss': [0.0837942361831665, 0.09993716329336166, 0.10555236041545868, 0.08590563386678696, 0.08233466744422913], 'accuracy': [0.9703518748283386, 0.9673156142234802, 0.9614216685295105, 0.9660653471946716, 0.9707090258598328]}\n",
      "{'loss': 0.8921600580215454, 'accuracy': 0.8516666889190674}\n",
      "{'loss': 0.8015182614326477, 'accuracy': 0.840833306312561}\n",
      "{'loss': 0.698546826839447, 'accuracy': 0.8650000095367432}\n",
      "{'loss': 0.5467669367790222, 'accuracy': 0.8583333492279053}\n",
      "{'loss': 0.7130996584892273, 'accuracy': 0.8641666769981384}\n",
      "{'loss': 0.6597335934638977, 'accuracy': 0.8583333492279053}\n",
      "{'loss': 0.851719081401825, 'accuracy': 0.862500011920929}\n",
      "{'loss': 0.997362494468689, 'accuracy': 0.815833330154419}\n",
      "{'loss': 0.7962918281555176, 'accuracy': 0.871666669845581}\n",
      "{'loss': 0.9650928974151611, 'accuracy': 0.8391666412353516}\n"
     ]
    }
   ],
   "source": [
    "train_history = []\n",
    "for each in train_history_list['secondary']:\n",
    "  print(each.history)\n",
    "  train_history.append(each.history)\n",
    "\n",
    "val_history = []\n",
    "for each in val_history_list['secondary']:\n",
    "  print(each)\n",
    "  val_history.append(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "finnish-addiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(losses_dir+'train_history_secondary2.json','w') as f0:\n",
    "  json.dump(train_history,f0)\n",
    "\n",
    "with open(losses_dir+'val_history_secondary2.json','w') as f0:\n",
    "  json.dump(val_history,f0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "moved-bishop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_history.json\n",
      "train_history_secondary.json\n",
      "train_history_secondary2.json\n",
      "val_history.json\n",
      "val_history_secondary.json\n",
      "val_history_secondary2.json\n"
     ]
    }
   ],
   "source": [
    "for each in os.listdir(base_dir+'losses/'):\n",
    "  print(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "corporate-avatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "train_accuracy = []\n",
    "val_accuracy = []\n",
    "val_loss = []\n",
    "\n",
    "with open(losses_dir+'train_history.json','r') as f0:\n",
    "  file0 = json.load(f0)\n",
    "\n",
    "for each in file0:\n",
    "    train_loss+=each['loss']\n",
    "    train_accuracy+=each['accuracy']\n",
    "\n",
    "\n",
    "with open(losses_dir+'train_history_secondary.json','r') as f0:\n",
    "  file2 = json.load(f0)\n",
    "\n",
    "for each in file2:\n",
    "    train_loss+=each['loss']\n",
    "    train_accuracy+=each['accuracy']\n",
    "    \n",
    "with open(losses_dir+'train_history_secondary2.json','r') as f0:\n",
    "  file21 = json.load(f0)\n",
    "\n",
    "for each in file21:\n",
    "    train_loss+=each['loss']\n",
    "    train_accuracy+=each['accuracy']\n",
    "    \n",
    "with open(losses_dir+'val_history.json','r') as f0:\n",
    "  file3 = json.load(f0)\n",
    "\n",
    "for each in file3:\n",
    "    val_loss.append(each['loss'])\n",
    "    val_accuracy.append(each['accuracy'])\n",
    "    \n",
    "\n",
    "with open(losses_dir+'val_history_secondary.json','r') as f0:\n",
    "  file5 = json.load(f0)\n",
    "\n",
    "for each in file5:\n",
    "    val_loss.append(each['loss'])\n",
    "    val_accuracy.append(each['accuracy'])\n",
    "    \n",
    "with open(losses_dir+'val_history_secondary2.json','r') as f0:\n",
    "  file52 = json.load(f0)\n",
    "\n",
    "for each in file52:\n",
    "    val_loss.append(each['loss'])\n",
    "    val_accuracy.append(each['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "latin-director",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x275dc332ac0>]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(range(len(train_loss))),train_loss,'g',label='training loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "sporting-private",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x275e1338ca0>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(range(len(train_accuracy))),train_accuracy,'b',label='training accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "hybrid-trial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x275e1bf55b0>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(range(len(val_accuracy))),val_accuracy,'b',label='val accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "homeless-profession",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(model_save+'17_secondary.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cosmetic-stock",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 42s 1s/step - loss: 0.6554 - accuracy: 0.8492\n"
     ]
    }
   ],
   "source": [
    "history = model.evaluate(x=test_generator,\n",
    "                             verbose=1,\n",
    "                             return_dict = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-transaction",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
